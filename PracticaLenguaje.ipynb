{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practida: Detección de lenguaje usanto NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cruz David Hernandez Antunez 15111430"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python es uno de los lenguajes de programacion mas potentes y populares. Como hemos visto hasta el dia de hoy se puede utilizar de muchas formas. Entre una de estas formas, se incluye la deteccion de idiomas. Es aquí en donde entran los algoritmos de PLN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de PLN tiene que modificarse para diferentes corpus y de acuerdo con la gramatica de diferentes idiomas. De acuerdo con el idioma que se este utilizando para realizar PLN, es el software o librerias que se debe seleccionar. Por ejemplo. NLTK es la librería de procesamiento de lenguaje natural mas utilizada para el idioma ingles en python. Sin embargo, Freeling es de las mejores alternativas cuando estamos trabajando con español."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La eficiencia del procesamiento de lenguaje natural depende de varios fatores. Un modelo con una calidad superior para el analisis de texto debe incluir lo siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Extraccion del texto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El texto puede extraerse mediante desde una página o datos web, importandolo en un formato particular, tomandolo desde una base de datos u a través de una API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Identificacion del texto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es el proceso de separacion de texto relevante o de interes, del texto que nos añade ruido al analisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Procesamiento de Lenguaje Natural (PLN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es el conjunto de algoritmos que admiten el procesamiento de diferentes idiomas o lenguajes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.- Aprendizaje automatico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un paso esencial para lograr objetivos como la colaboracion, el analisis de sentimientos y agrupacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinacion de python y NLTK para la deteccion de lenguaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoria de las personas utilizan motores de busqueda y redes sociales. Los cuales se muestran en diferentes lenguajes. Entre ellos español e inglés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lograr este proceso, un texto indexado debe examinar bien, lo que da como resultado el contenido mostrado por estos motores y redes sociales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen muchas maneras de lograr este objetivo, la forma mas facil de hacerlos es mediante el enfoque basado en \"stop Words\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"StopWords\" se usa n el procesamiento de lenguaje natural para mencionar palabras que se deben filtrar del texto antes de que tenga lugar cualquier tipo de procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, tenemos un texto para detectar el idioma. El paso básico es Tokenizar el texto dado una lista de \"palabras\" y \"tokens\", utilizando un enfoque que depende de los requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El siguiente ejemplo de deteccion de lenguaje utiliza NLTK y Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LazyCorpusLoader' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9c4b3117c291>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0minput4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Hallo mein name ist Samuel Martinez\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mlanguage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_language\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'cadena de texto:'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0minput1\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m'\\t Lenguaje'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-9c4b3117c291>\u001b[0m in \u001b[0;36mdetect_language\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#funcion que detecta lenguaje\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdetect_language\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mratios\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlang_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mlanguage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mratios\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-9c4b3117c291>\u001b[0m in \u001b[0;36mlang_ratio\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mstopwords_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mwords_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mcommon_elements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mlang_ratio\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcommon_elements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'LazyCorpusLoader' object is not iterable"
     ]
    }
   ],
   "source": [
    "from nltk import *\n",
    "from nltk.corpus import *\n",
    "#\n",
    "def lang_ratio(input):\n",
    "    lang_ratio={}\n",
    "    tokens = wordpunct_tokenize(input)\n",
    "    for language in stopwords.fileids():\n",
    "        stopwords_set = set(stopwords.words(language))\n",
    "        words_set = set(words)\n",
    "        common_elements = words_set.intersection(stopwords_set)\n",
    "        lang_ratio[language] = len (common_elements)\n",
    "    return lang_ratio\n",
    "#funcion que detecta lenguaje \n",
    "def detect_language(input):\n",
    "    ratios=lang_ratio(input)\n",
    "    language = max(ratios, key=ratios.get)\n",
    "    return language\n",
    "input1 = \"hello my name is Samuel Martinez\"\n",
    "input2 = \"Hola mi nombre es Samuel Martinez\"\n",
    "input3 = \"Bonjour mon nom est Samuel Martinez\"\n",
    "input4 = \"Hallo mein name ist Samuel Martinez\"\n",
    "\n",
    "language = detect_language(input1)\n",
    "print ('cadena de texto:'+ input1+ '\\t Lenguaje'+ language)\n",
    "\n",
    "language = detect_language(input2)\n",
    "print ('cadena de texto ' + input2 + '\\Lenguaje: ' + language)\n",
    "\n",
    "language = detect_language(input3)\n",
    "print ('cadena de texto ' + input3+ '\\Lenguaje: ' + language)\n",
    "                           \n",
    "language = detect_language(input4)\n",
    "print ('cadena de texto ' + input4+ '\\Lenguaje: ' + language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
